AI-Agentic Cursor & SRP Guide

1. AI-Agentic Cursor Context

A codebase optimized for LLMs, with clear separation of concerns, self-healing, and step-wise refactoring.

A. Environment

Shell: powershell.exe on Win32 (Windows path style)

normalizePaths: true

B. Proactive Autonomy

Self-Diagnose & Fix: On any error or misconfiguration, Cursor must:

Detect root cause

Apply the fix automatically

Explain the change and its intent

Iterate until resolved or a true external blocker emerges

No User Delegation: Never ask the user to troubleshoot.

C. General Principles

Scan First: Always read the codebase before asking questions.

Code for AI: Prioritize clarity, redundancy, and explicitness; avoid clever or implicit tricks.

No Dev Server: Don't run unless the user asks.

D. File Structure Rules

Single Concept: Max 500 lines or 6K chars per file.

One Domain Unit: No catch-all utils or index hubs.

Domain Folders: Organize by feature or domain, not generic categories.

E. TypeScript Practices

Use type over interface unless extending libraries.

Keep Types Simple: Avoid deeply nested generics or conditional types.

Names Reflect Meaning: Types express domain context, not implementation.

F. Function Design

VerbNoun Names: loadUser, fetchReport.

Max 3–4 Parameters: Prefer object destructuring.

Explicit Returns: Always annotate return shapes with named types.

Pure by Default: Side effects only if clearly named (e.g., logAndSend).

G. Naming & Semantics

Human-Readable: No single letters or vague names.

Extract Constants: Move all magic values into named constants.

H. Comments & Docblocks

Doc Comments on Exports: Purpose-first, explaining "why."

Anchor Complex Logic: Use comments to capture intent.

I. Modules & Dependencies

No Circular Imports.

Explicit Imports Only: No star or side-effect imports.

Layering: High-level modules never import from lower layers.

J. Error Handling

Contextual Messages: Never empty catch blocks.

Actionable Errors: Explain what failed and why.

K. LLM Editability Guarantees

Small Chunks: Break complex logic into named functions.

Tag Temporary Code: Use // FIXME: or // TEMP: with reason.

No Hidden Logic: Everything in its own function.

L. MCPs & Context7

Limit to 7 Domains: If more needed, segment and confirm priorities.

Inline Tags: // CONTEXT: Auth, // FOCUS: TokenValidation.

M. Sequential Prompt Flow

Step 1: Understand Intent

Step 2: Locate Mechanism

Step 3: Rewrite or Suggest

Use commands:

@plan → outline steps

@explain → describe current behavior

@rewrite → apply refactor steps

2. Single Responsibility Principle (SRP) for LLM Projects

Each file or module has exactly one reason to change.

A. Core Module Types

Prompts: Raw templates and system messages (prompts/*.ts).

Validation: Input sanitization and schemas (validation/*.js).

LLM Client: API wrapper with retries and auth (services/llmClient.py).

Parsing: Turn completions into structured data (parsers/*.rb).

Orchestration: Business logic tying prompts → client → parser (controllers/*.go).

UI: Rendering outputs and interactivity (components/*.jsx).

Errors/Logging: Centralized error handling (middleware/*.ts).

Tests/Mocks: Unit tests with LLM response mocks (tests/*.ts).

B. Example Folder Structure

src/
├── prompts/
├── validation/
├── services/
├── parsers/
├── controllers/
├── components/
├── middleware/
└── tests/

C. SRP Checklist

One Reason to Change: Can you summarize responsibility in one sentence?

No Unrelated Imports: Only depend on modules within your responsibility.

Meaningful Name: File name matches its sole purpose.

Easy to Test: Dependencies can be stubbed or mocked.

D. Refactoring Best Practices

Preserve Behavior: No change to outputs or public interfaces.

Extract, Don't Re-engineer: Cut existing code into focused files, then aggregate.

Small Steps: Refactor one module at a time, verifying before proceeding.

Separate Hats: Don't mix refactoring with feature or bug-fix commits.

3. Additional Operational Practices

3.1 Prompt Versioning & Change Tracking

Tag prompt files with metadata: version, author, date, summary.

Store changelogs alongside templates for auditability.

3.2 Metrics, Monitoring & Cost Awareness

Instrument LLM client to emit token usage, latency, and error metrics.

Integrate cost dashboards or alerts for spending thresholds.

Add profiling hooks to identify slow or expensive calls.

3.3 Security & Privacy

Sanitize inputs/outputs to redact PII or sensitive data.

Enforce a pre-send "sanitizer" module to strip secrets.

Audit dependencies; forbid unmaintained or vulnerable SDKs.

3.4 CI/CD & Automation

Lint and format prompt templates (e.g., placeholder consistency).

Automated contract tests: stub LLM calls to verify workflows.

CI pipeline validating prompt → API → parser → UI end-to-end.

3.5 Collaboration & Review Process

Require PRs for prompt or parser changes with peer review.

Enforce changelog-style commit messages: docs(prompts): bump to v1.2.

3.6 Observability & Alerting

Centralize logs of model errors and unexpected outputs.

Define SLIs/SLOs for response time and output quality (e.g. parse-error rate).

3.7 Testing Standards

Use "golden-prompt" integration tests: verify critical fields in completions.

Validate parsed outputs against JSON Schema or equivalent.

3.8 UI & CSS Debugging Best Practices

Consistent Naming: Ensure CSS selectors exactly match component class names (talent-tooltip vs .tooltip).

Cache Busting: Instruct developers to hard-refresh or disable cache when updating styles; include a note in project README.

DevTools Inspection: Regularly inspect elements to verify which rules apply and identify specificity conflicts or overrides.

CSS Variables: Centralize colors, spacing, and accent values in a shared variables file to avoid duplication and simplify theme changes.

Responsive Flipping: Implement tooltip auto-flip logic (above → below → right → left) to prevent obscuring target elements.

Automated Linting: Add CSS linters (e.g., stylelint) to CI to catch unused selectors, duplicate rules, or typos.

$1

4. CSS Styles Conflict: Root Cause & Future Prevention

4.1 Issue Summary

A recent tooltip styling update failed to apply due to:

Conflicting Definitions: Legacy tooltip rules in nodes.css targeting .tooltip and .talent-tooltip overrode new styles in tooltip.css.

Missing Dependencies: tooltip.css relied on undefined CSS variables (--tier-accent) from variables.css, which wasn't being loaded.

Load Order: nodes.css was imported after tooltip.css, causing cascade overrides.

4.2 Prevention Strategies

Strict File Responsibility:

variables.css → only CSS custom properties.

tooltip.css   → only tooltip styles.

nodes.css     → only node/grid styles.

Clear Import Order:

<link rel="stylesheet" href="/styles/variables.css">
<link rel="stylesheet" href="/styles/grid.css">
<link rel="stylesheet" href="/styles/nodes.css">
<link rel="stylesheet" href="/styles/tooltip.css">

Namespacing Classes:

Use talent-tooltip instead of generic tooltip to avoid collisions.

Prefix variables with --tt- for tooltip-specific tokens.

Dependency Validation:

Add a CI check to ensure all var(--*) usages have corresponding definitions in variables.css.

Conflict Detection:

Use a build step or linter (e.g., stylelint) to detect duplicate selectors across CSS files.

Documentation & Onboarding:

Update README with CSS file roles and import guidelines.

Include a "CSS Debugging" quick reference in project docs.

By codifying these steps in our Cursor context, future style updates will apply reliably, and conflicts will be caught early in development.

4.9 Visual Pathfinding & UI Logic

- Visual pathfinding (e.g., for SVG edge/connector rendering) must always traverse the actual node graph as defined in the data, regardless of progression or allocation rules.
- Do NOT filter out node types (e.g., minors) in visual pathfinding unless the data structure guarantees direct connections between major nodes.
- Allocation/progression logic may be stricter, but visual/UX logic must always reflect the real graph structure to avoid invisible or broken UI elements.
- When updating progression rules, always review and test visual pathfinding to ensure connector paths remain visible and correct.
- Add regression tests or debug logging to catch cases where no path is found due to overly strict filters.

4.10 Implementation Directness

- When a user requests a feature or fix, implement the simplest and most effective method immediately.
- Do NOT present multiple options or ask for clarification unless the request is genuinely ambiguous or requires user input that cannot be inferred.
- Prioritize direct implementation over discussion of alternatives.
- If multiple approaches exist, choose the most straightforward and reliable method.
- Only ask questions when the user's intent cannot be determined from context or when user input is required (e.g., API keys, configuration values).
- Focus on delivering working solutions rather than explaining trade-offs unless specifically requested.

